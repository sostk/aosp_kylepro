diff -ur a/packages/apps/Dialer/src/com/android/dialer/DialtactsActivity.java b/packages/apps/Dialer/src/com/android/dialer/DialtactsActivity.java
--- a/packages/apps/Dialer/src/com/android/dialer/DialtactsActivity.java	2015-04-15 01:33:37.000000000 +0545
+++ b/packages/apps/Dialer/src/com/android/dialer/DialtactsActivity.java	2016-05-16 21:43:43.768132081 +0545
@@ -162,6 +162,13 @@
      */
     private Animation mSlideOut;
 
+    AnimationListenerAdapter mSlideInListener = new AnimationListenerAdapter() {
+        @Override
+        public void onAnimationEnd(Animation animation) {
+            maybeEnterSearchUi();
+        }
+    };
+
     /**
      * Listener for after slide out animation completes on dialer fragment.
      */
@@ -295,7 +302,7 @@
                 final boolean sameSearchMode = (mIsDialpadShown && mInDialpadSearch) ||
                         (!mIsDialpadShown && mInRegularSearch);
                 if (!sameSearchMode) {
-                    enterSearchUi(mIsDialpadShown, mSearchQuery);
+                    enterSearchUi(mIsDialpadShown, mSearchQuery, true /* animate */);
                 }
             }
 
@@ -320,7 +327,8 @@
         public void onClick(View v) {
             if (!isInSearchUi()) {
                 mActionBarController.onSearchBoxTapped();
-                enterSearchUi(false /* smartDialSearch */, mSearchView.getText().toString());
+                enterSearchUi(false /* smartDialSearch */, mSearchView.getText().toString(),
+                        true /* animate */);
             }
         }
     };
@@ -431,6 +439,8 @@
         mSlideIn.setInterpolator(AnimUtils.EASE_IN);
         mSlideOut.setInterpolator(AnimUtils.EASE_OUT);
 
+        mSlideIn.setAnimationListener(mSlideInListener);
+
         mSlideOut.setAnimationListener(mSlideOutListener);
 
         mParentLayout = (FrameLayout) findViewById(R.id.dialtacts_mainlayout);
@@ -667,12 +677,11 @@
             mFloatingActionButtonController.scaleOut();
         } else {
             mFloatingActionButtonController.setVisible(false);
+            maybeEnterSearchUi();
         }
         mActionBarController.onDialpadUp();
 
-        if (!isInSearchUi()) {
-            enterSearchUi(true /* isSmartDial */, mSearchQuery);
-        }
+        mListsFragment.getView().animate().alpha(0).withLayer();
     }
 
     /**
@@ -887,7 +896,7 @@
     /**
      * Shows the search fragment
      */
-    private void enterSearchUi(boolean smartDialSearch, String query) {
+    private void enterSearchUi(boolean smartDialSearch, String query, boolean animate) {
         if (mStateSaved || getFragmentManager().isDestroyed()) {
             // Weird race condition where fragment is doing work after the activity is destroyed
             // due to talkback being on (b/10209937). Just return since we can't do any
@@ -916,7 +925,11 @@
         mInRegularSearch = !smartDialSearch;
 
         SearchFragment fragment = (SearchFragment) getFragmentManager().findFragmentByTag(tag);
-        transaction.setCustomAnimations(android.R.animator.fade_in, 0);
+        if (animate) {
+            transaction.setCustomAnimations(android.R.animator.fade_in, 0);
+        } else {
+            transaction.setTransition(FragmentTransaction.TRANSIT_NONE);
+        }
         if (fragment == null) {
             if (smartDialSearch) {
                 fragment = new SmartDialSearchFragment();
@@ -930,10 +943,14 @@
         // DialtactsActivity will provide the options menu
         fragment.setHasOptionsMenu(false);
         fragment.setShowEmptyListForNullQuery(true);
-        fragment.setQueryString(query, false /* delaySelection */);
+        if (!smartDialSearch) {
+            fragment.setQueryString(query, false /* delaySelection */);
+        }
         transaction.commit();
 
-        mListsFragment.getView().animate().alpha(0).withLayer();
+        if (animate) {
+            mListsFragment.getView().animate().alpha(0).withLayer();
+        }
         mListsFragment.setUserVisibleHint(false);
     }
 
@@ -991,6 +1008,12 @@
         }
     }
 
+    private void maybeEnterSearchUi() {
+        if (!isInSearchUi()) {
+            enterSearchUi(true /* isSmartDial */, mSearchQuery, false);
+        }
+    }
+
     /**
      * @return True if the search UI was exited, false otherwise
      */
Only in b/packages/apps/Dialer/src/com/android/dialer: DialtactsActivity.java~
diff -ur a/frameworks/av/include/media/stagefright/ColorConverter.h b/frameworks/av/include/media/stagefright/ColorConverter.h
--- a/frameworks/av/include/media/stagefright/ColorConverter.h	2016-02-09 07:51:37.610025648 +0000
+++ b/frameworks/av/include/media/stagefright/ColorConverter.h	2016-02-09 07:57:33.894025648 +0000
@@ -67,6 +67,9 @@
     status_t convertCbYCrY(
             const BitmapParams &src, const BitmapParams &dst);
 
+    status_t convertYCbYCr(
+            const BitmapParams &src, const BitmapParams &dst);
+
     status_t convertYUV420Planar(
             const BitmapParams &src, const BitmapParams &dst);
 
diff -ur a/frameworks/av/media/libstagefright/ACodec.cpp b/frameworks/av/media/libstagefright/ACodec.cpp
--- a/frameworks/av/media/libstagefright/ACodec.cpp	2016-02-09 07:51:37.478025648 +0000
+++ b/frameworks/av/media/libstagefright/ACodec.cpp	2016-02-09 07:57:33.898025648 +0000
@@ -604,11 +604,7 @@
 
     status_t err;
     if (mNativeWindow != NULL && portIndex == kPortIndexOutput) {
-        if (mStoreMetaDataInOutputBuffers) {
-            err = allocateOutputMetaDataBuffers();
-        } else {
-            err = allocateOutputBuffersFromNativeWindow();
-        }
+        err = allocateOutputBuffersFromNativeWindow();
     } else {
         OMX_PARAM_PORTDEFINITIONTYPE def;
         InitOMXParams(&def);
@@ -736,11 +732,33 @@
             frameHeight,
             def.format.video.eColorFormat);
 #else
+
+    OMX_COLOR_FORMATTYPE HalColorFormat;
+    status_t omxresuilts;
+    
+    ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: %i", def.format.video.eColorFormat);
+    switch (def.format.video.eColorFormat) {
+        case OMX_COLOR_FormatYCbYCr:
+            ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: OMX_COLOR_FormatYCbYCr (%i) -> (%i)", OMX_COLOR_FormatYCbYCr, OMX_COLOR_FormatYUV420Planar);
+            def.format.video.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+            omxresuilts = mOMX->setParameter(mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+            if (omxresuilts != OK) {
+                ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow setParameter(OMX_IndexParamPortDefinition) ERROR");
+            }
+            ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: OMX_COLOR_FormatYCbYCr (%i) -> (%i) -> HAL_PIXEL_FORMAT_YV12 (%i)", OMX_COLOR_FormatYCbYCr, OMX_COLOR_FormatYUV420Planar, (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12);
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        default:
+            ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: default(%i) -> HAL_PIXEL_FORMAT_YV12 (%i)", def.format.video.eColorFormat, (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12);
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+    }
+
     err = native_window_set_buffers_geometry(
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
-            def.format.video.eColorFormat);
+            HalColorFormat);
 #endif
 
     if (err != 0) {
@@ -1963,6 +1981,9 @@
         err = setMinBufferSize(kPortIndexInput, (size_t)maxInputSize);
     } else if (!strcmp("OMX.Nvidia.aac.decoder", mComponentName.c_str())) {
         err = setMinBufferSize(kPortIndexInput, 8192);  // XXX
+    }else if (!strncmp(mComponentName.c_str(), "OMX.brcm.video.h264.hw.decoder", 30)) {
+        ALOGE("PATCH:ACodec:configureCodec:[%s] setMinBufferSize", mComponentName.c_str());
+        setMinBufferSize(kPortIndexInput, (1080 * 720 * 3) / 2);
     }
 
     mBaseOutputFormat = outputFormat;
diff -ur a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
--- a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp	2016-02-09 07:51:37.470025648 +0000
+++ b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp	2016-02-09 07:57:33.902025648 +0000
@@ -44,6 +44,7 @@
     switch (mSrcFormat) {
         case OMX_COLOR_FormatYUV420Planar:
         case OMX_COLOR_FormatCbYCrY:
+        case OMX_COLOR_FormatYCbYCr:
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
         case OMX_COLOR_FormatYUV420SemiPlanar:
         case OMX_TI_COLOR_FormatYUV420PackedSemiPlanar:
@@ -110,6 +111,10 @@
             err = convertCbYCrY(src, dst);
             break;
 
+        case OMX_COLOR_FormatYCbYCr:
+            err = convertYCbYCr(src, dst);
+            break;
+
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
             err = convertQCOMYUV420SemiPlanar(src, dst);
             break;
@@ -159,6 +164,71 @@
 
             signed u_b = u * 517;
             signed u_g = -u * 100;
+            signed v_g = -v * 208;
+            signed v_r = v * 409;
+
+            signed tmp1 = y1 * 298;
+            signed b1 = (tmp1 + u_b) / 256;
+            signed g1 = (tmp1 + v_g + u_g) / 256;
+            signed r1 = (tmp1 + v_r) / 256;
+
+            signed tmp2 = y2 * 298;
+            signed b2 = (tmp2 + u_b) / 256;
+            signed g2 = (tmp2 + v_g + u_g) / 256;
+            signed r2 = (tmp2 + v_r) / 256;
+
+            uint32_t rgb1 =
+                ((kAdjustedClip[r1] >> 3) << 11)
+                | ((kAdjustedClip[g1] >> 2) << 5)
+                | (kAdjustedClip[b1] >> 3);
+
+            uint32_t rgb2 =
+                ((kAdjustedClip[r2] >> 3) << 11)
+                | ((kAdjustedClip[g2] >> 2) << 5)
+                | (kAdjustedClip[b2] >> 3);
+
+            if (x + 1 < src.cropWidth()) {
+                *(uint32_t *)(&dst_ptr[x]) = (rgb2 << 16) | rgb1;
+            } else {
+                dst_ptr[x] = rgb1;
+            }
+        }
+
+        src_ptr += src.mWidth * 2;
+        dst_ptr += dst.mWidth;
+    }
+
+    return OK;
+}
+
+status_t ColorConverter::convertYCbYCr(
+        const BitmapParams &src, const BitmapParams &dst) {
+        ALOGE("PATCH:ColorConverter:convertYCbYCr");
+    // XXX Untested
+
+    uint8_t *kAdjustedClip = initClip();
+
+    if (!((src.mCropLeft & 1) == 0
+        && src.cropWidth() == dst.cropWidth()
+        && src.cropHeight() == dst.cropHeight())) {
+        return ERROR_UNSUPPORTED;
+    }
+
+    uint16_t *dst_ptr = (uint16_t *)dst.mBits
+        + dst.mCropTop * dst.mWidth + dst.mCropLeft;
+
+    const uint8_t *src_ptr = (const uint8_t *)src.mBits
+        + (src.mCropTop * dst.mWidth + src.mCropLeft) * 2;
+
+    for (size_t y = 0; y < src.cropHeight(); ++y) {
+        for (size_t x = 0; x < src.cropWidth(); x += 2) {
+            signed y1 = (signed)src_ptr[2 * x ] - 16;
+            signed y2 = (signed)src_ptr[2 * x + 2] - 16;
+            signed u = (signed)src_ptr[2 * x + 1] - 128;
+            signed v = (signed)src_ptr[2 * x + 3] - 128;
+
+            signed u_b = u * 517;
+            signed u_g = -u * 100;
             signed v_g = -v * 208;
             signed v_r = v * 409;
 
diff -ur a/frameworks/av/media/libstagefright/MPEG4Writer.cpp b/frameworks/av/media/libstagefright/MPEG4Writer.cpp
--- a/frameworks/av/media/libstagefright/MPEG4Writer.cpp	2016-02-09 07:51:37.470025648 +0000
+++ b/frameworks/av/media/libstagefright/MPEG4Writer.cpp	2016-02-09 07:57:33.906025648 +0000
@@ -2298,8 +2298,6 @@
 
         timestampUs -= previousPausedDurationUs;
         if (WARN_UNLESS(timestampUs >= 0ll, "for %s track", trackName)) {
-            copy->release();
-            return ERROR_MALFORMED;
         }
 
         if (!mIsAudio) {
@@ -2314,8 +2312,6 @@
             cttsOffsetTimeUs =
                     timestampUs - decodingTimeUs;
             if (WARN_UNLESS(kMaxCttsOffsetTimeUs >= decodingTimeUs - timestampUs, "for %s track", trackName)) {
-                copy->release();
-                return ERROR_MALFORMED;
             }
 
             timestampUs = decodingTimeUs;
@@ -2326,8 +2322,6 @@
             currCttsOffsetTimeTicks =
                     (cttsOffsetTimeUs * mTimeScale + 500000LL) / 1000000LL;
             if (WARN_UNLESS(currCttsOffsetTimeTicks <= 0x0FFFFFFFFLL, "for %s track", trackName)) {
-                copy->release();
-                return ERROR_MALFORMED;
             }
 
             if (mStszTableEntries->count() == 0) {
@@ -2368,8 +2362,6 @@
         }
 
         if (WARN_UNLESS(timestampUs >= 0ll, "for %s track", trackName)) {
-            copy->release();
-            return ERROR_MALFORMED;
         }
 
         ALOGV("%s media time stamp: %" PRId64 " and previous paused duration %" PRId64,
@@ -2389,12 +2381,6 @@
         if (currDurationTicks < 0ll) {
             ALOGE("timestampUs %" PRId64 " < lastTimestampUs %" PRId64 " for %s track",
                 timestampUs, lastTimestampUs, trackName);
-            copy->release();
-            err = UNKNOWN_ERROR;
-            mSource->notifyError(err);
-            copy->release();
-            copy = NULL;
-            return err;
         }
 
         // if the duration is different for this sample, see if it is close enough to the previous
@@ -2492,7 +2478,6 @@
     }
 
     if (isTrackMalFormed()) {
-        err = ERROR_MALFORMED;
     }
 
     mOwner->trackProgressStatus(mTrackId, -1, err);
diff -ur a/frameworks/av/media/libstagefright/OMXCodec.cpp b/frameworks/av/media/libstagefright/OMXCodec.cpp
--- a/frameworks/av/media/libstagefright/OMXCodec.cpp	2016-02-09 07:51:37.050025648 +0000
+++ b/frameworks/av/media/libstagefright/OMXCodec.cpp	2016-02-09 07:57:33.910025648 +0000
@@ -1713,6 +1713,12 @@
 #endif
 
         int32_t colorFormat;
+
+        if (!strncmp("OMX.brcm.video.h264.hw.decoder", mComponentName, 30)) {
+            ALOGE("PATCH:OMXCodec:setVideoOutputFormat[%s] colorFormat = %i FOUND BRCM set 19", mComponentName, colorFormat);
+            format.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+        }
+
         if (meta->findInt32(kKeyColorFormat, &colorFormat)
                 && colorFormat != OMX_COLOR_FormatUnused
                 && colorFormat != format.eColorFormat) {
@@ -1725,6 +1731,10 @@
                 if (format.eColorFormat == colorFormat) {
                     break;
                 }
+                if(err == 0x80001005){
+                    ALOGE("PATCH:OMXCodec:setVideoOutputFormat[%s] getParameter(OMX_IndexParamVideoPortFormat) colorFormat(%i) != format.eColorFormat (%i) OMX_ErrorNoMore", mComponentName, colorFormat, format.eColorFormat);
+                    err = OMX_ErrorNoMore;
+                }
             }
             if (format.eColorFormat != colorFormat) {
                 CODEC_LOGE("Color format %d is not supported", colorFormat);
@@ -1755,11 +1765,7 @@
 
 #if 1
     // XXX Need a (much) better heuristic to compute input buffer sizes.
-#ifdef USE_SAMSUNG_COLORFORMAT
     const size_t X = 64 * 8 * 1024;
-#else
-    const size_t X = 64 * 1024;
-#endif
     if (def.nBufferSize < X) {
         def.nBufferSize = X;
     }
@@ -2299,11 +2305,37 @@
             frameHeight,
             def.format.video.eColorFormat);
 #else
+
+    ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow def.format.video.eColorFormat = %i", def.format.video.eColorFormat);
+
+    OMX_COLOR_FORMATTYPE HalColorFormat;
+    status_t errss;
+    
+    switch (def.format.video.eColorFormat) {
+        case OMX_COLOR_FormatYCbYCr:
+            ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow OMX_COLOR_FormatYCbYCr(%i) -> (%i)", OMX_COLOR_FormatYCbYCr, OMX_COLOR_FormatYUV420Planar);
+            def.format.video.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+            errss = mOMX->setParameter(mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+            if (errss != OK){
+                ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow setParameter failed: %d", errss);
+            }
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        case OMX_COLOR_FormatYUV420Planar:
+            ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow OMX_COLOR_FormatYUV420Planar(%i) -> HAL_PIXEL_FORMAT_YV12(%i)", OMX_COLOR_FormatYUV420Planar, (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12);
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        default:
+            ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow default(%i) -> default(%i)", def.format.video.eColorFormat, def.format.video.eColorFormat);
+            HalColorFormat = def.format.video.eColorFormat;
+        break;
+    }
+
     err = native_window_set_buffers_geometry(
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
-            def.format.video.eColorFormat);
+            HalColorFormat);
 #endif
 
     if (err != 0) {
@@ -5470,7 +5502,13 @@
                     caps->mColorFormats.push(flexibleEquivalent);
                 }
             }
-            caps->mColorFormats.push(portFormat.eColorFormat);
+            if(portFormat.eColorFormat == OMX_COLOR_FormatYCbYCr) {
+                ALOGE("PATCH:OMXCodec:QueryCodec:getParameter(IndexParamVideoPortFormat) portFormat.eColorFormat %i SET %i", portFormat.eColorFormat, OMX_COLOR_FormatYUV420Planar);
+                caps->mColorFormats.push(OMX_COLOR_FormatYUV420Planar);
+            }else{
+                ALOGE("PATCH:OMXCodec:QueryCodec:getParameter(IndexParamVideoPortFormat) DEFAULT portFormat.eColorFormat %i", portFormat.eColorFormat);
+                caps->mColorFormats.push(portFormat.eColorFormat);
+            }
         }
     }
 diff -ur a/frameworks/native/libs/gui/BufferQueueProducer.cpp b/frameworks/native/libs/gui/BufferQueueProducer.cpp
--- a/frameworks/native/libs/gui/BufferQueueProducer.cpp	2016-02-09 07:51:36.702025648 +0000
+++ b/frameworks/native/libs/gui/BufferQueueProducer.cpp	2016-02-09 07:57:33.922025648 +0000
@@ -204,7 +204,12 @@
             const int newUndequeuedCount =
                 maxBufferCount - (dequeuedCount + 1);
             const int minUndequeuedCount =
+#ifdef HAWAII_HWC
+                // HACK: for some reason, we need to reduce min undequeue for screen recording
+                mCore->getMinUndequeuedBufferCountLocked(false);
+#else
                 mCore->getMinUndequeuedBufferCountLocked(async);
+#endif
             if (newUndequeuedCount < minUndequeuedCount) {
                 BQ_LOGE("%s: min undequeued buffer count (%d) exceeded "
                         "(dequeued=%d undequeued=%d)",
diff -ur a/frameworks/native/libs/gui/SensorEventQueue.cpp b/frameworks/native/libs/gui/SensorEventQueue.cpp
--- a/frameworks/native/libs/gui/SensorEventQueue.cpp	2016-02-09 07:51:36.714025648 +0000
+++ b/frameworks/native/libs/gui/SensorEventQueue.cpp	2016-02-09 07:57:33.922025648 +0000
@@ -130,8 +130,12 @@
 
 status_t SensorEventQueue::enableSensor(int32_t handle, int32_t samplingPeriodUs,
                                         int maxBatchReportLatencyUs, int reservedFlags) const {
-    return mSensorEventConnection->enableDisable(handle, true, us2ns(samplingPeriodUs),
+    status_t err = mSensorEventConnection->enableDisable(handle, true, us2ns(samplingPeriodUs),
                                                  us2ns(maxBatchReportLatencyUs), reservedFlags);
+    if (err == NO_ERROR) {
+        mSensorEventConnection->setEventRate(handle, us2ns(samplingPeriodUs));
+    }
+    return err;
 }
 
 status_t SensorEventQueue::flush() const {
diff -ur a/frameworks/native/libs/gui/SurfaceComposerClient.cpp b/frameworks/native/libs/gui/SurfaceComposerClient.cpp
--- a/frameworks/native/libs/gui/SurfaceComposerClient.cpp	2016-02-09 07:51:36.702025648 +0000
+++ b/frameworks/native/libs/gui/SurfaceComposerClient.cpp	2016-02-09 07:57:33.922025648 +0000
@@ -838,7 +838,7 @@
         uint32_t minLayerZ, uint32_t maxLayerZ, bool useIdentityTransform) {
     sp<ISurfaceComposer> s(ComposerService::getComposerService());
     if (s == NULL) return NO_INIT;
-#ifdef USE_MHEAP_SCREENSHOT
+#if defined(USE_MHEAP_SCREENSHOT) && !defined(HAWAII_HWC)
     int format = 0;
     producer->query(NATIVE_WINDOW_FORMAT,&format);
     if (format == PIXEL_FORMAT_RGBA_8888) {
diff -ur a/frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp b/frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp
--- a/frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp	2016-02-09 07:51:36.770025648 +0000
+++ b/frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp	2016-02-09 07:57:33.926025648 +0000
@@ -3748,6 +3748,11 @@
 {
     ATRACE_CALL();
 
+// Rotation artifact problems when useReadPixels is false
+#ifdef HAWAII_HWC
+    useReadPixels = true;
+#endif
+
     // get screen geometry
     const uint32_t hw_w = hw->getWidth();
     const uint32_t hw_h = hw->getHeight();
